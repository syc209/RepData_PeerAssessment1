p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
Xmean <- sum(temp["X",] * temp["Prob",])
Xmean
data(sleep)
head(sleep)
data(mtcars)
head(mtcars)
install.packages("t.test")
t.test(mtcars$mpg)
t.test(mtcars$mpg)$conf.int
round(t.test(mtcars$mpg)$conf.int)
qt(0.975, df=8)
round(qt(.975, df=8) * 1/3, 2)
x=c(mtcars$cyl==4)
head(x)
y=c(mtcars$cyl==6)
t.test(x,y, alt="less", var.equal=TRUE)
round(t.test(x-y)$conf.int)
mbv <- 1100
p <- 0.95
s <- 30
n <- 9
ci <- mbv + c(-1,1) * qt(p+(1-p)/2, n-1) * s / sqrt(n)
ci
mbv <- 1100
p <- 0.95
s <- 30
n <- 9
ci <- mbv + c(-1,1) * qt(p+(1-p)/2, n-1) * s / sqrt(n)
round(ci)
k <- 1000
install.packages("swirl")
library(swirl)
install_from_swirl("Statistical Inference")
hist(runif(1000))
mns = null
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
lamda <- 0.2
sample <- 40
simu <- 1000
set.seed(800)
Means <- data.frame(x = sapply(simu, function(x) {
mean(rexp(n, lambda))
}))
m <- mean(Means$x)
lamda <- 0.2
sample <- 40
simu <- 1000
set.seed(800)
Means <- data.frame(x = sapply(simu, function(x) {
mean(rexp(n, lambda))
}))
Means <- data.frame(x = sapply(simu, function(x) {
mean(rexp(sample, lambda))
}))
m <- mean(Means$x)
lamda <- 0.2
sample <- 40
simu <- 1000
set.seed(800)
Means <- data.frame(x = sapply(simu, function(x) {
mean(rexp(sample, lambda))
}))
set.seed(800)
lambda <- 0.2
n <- 40
simulations <- 1000
Means <- data.frame(x = sapply(simulations, function(x) {
mean(rexp(n, lambda))
}))
m <- mean(Means$x)
m
head(Means)
set.seed(820)
lambda <- 0.2
n <- 40
simulations <- 1000
Means <- data.frame(x = sapply(simulations, function(x) {
mean(rexp(n, lambda))
}))
m <- mean(Means$x)
m
set.seed(80)
lambda <- 0.2
n <- 40
simulations <- 1000
Means <- data.frame(x = sapply(simulations, function(x) {
mean(rexp(n, lambda))
}))
m <- mean(Means$x)
m
head(Means)
(1/lambda)/sqrt(40)
((1/lambda)/sqrt(40))^2
var <- var(Means$x)
var
variance <- var(Means$x)
variance
var(Means$x)
m <- mean(Means$x)
sd <- sd(Means$x)
variance <- var(Means$x)
m
sd
variance
sd(Means$x)
var(Means$x)
mean(Means$x)
sd(Means$x)
x
Means
x
set.seed(80)
lambda <- 0.2
n <- 40
simulations <- 1000
Means <- data.frame(x = sapply(simulations, function(x) {
mean(rexp(n, lambda))
}))
m <- mean(Means$x)
m
1/lambda
m <- mean(Means$x)
m
(1/lambda)/sqrt(40)
((1/lambda)/sqrt(40))^2
(1/lambda)/sqrt(n)
((1/lambda)/sqrt(n))^2
var(Means$x)
variance <- var(Means$x)
variance
variance <- var(Means)
variance
variance <- var(Means$x)
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
library(swirl)
ls()
rm(list=ls())
library(swirl)
install_from_swirl("Statistical Inference")
swirl()
33/36
deck
13*4
4/52
(1/52)^4
0
16/52
12/52
11/51*1/3
11/51*1/2
(11/51)*0.5
(11/51)*1/3
22/51
2/51
2.28
.8*1.6
.8*1.6/2
0.64/2
0.64/1
mypdf
integrate(mypdf)
?integrate
integrate(mypdf, 0, 1.6)
0.5
x^2=4*.5=2
quantile(x, c(.5))
info()
quantile(x^2=4*.5=2, 0.5)
quantile(x^2, 0.5)
equiv_val(sqrt(2))
1.414214
.997*.001
.998*.001
(1-.985)*(1-.997)
(1-.985)*(1-.001)
.997*.001/(.997*.001+0.014985)
3.5
expect_dic
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
E((X_hi + X_lo)/2)
.5 *( E(X_hi)+E(X_lo)
.5*(edh+edl)
myfunc
integrate(myfunc,0,2)
myfunc
spop
mean(spop)
allsam
apply(allsam, 1, mean)
smeans
integrate(myfunc,0,2)
mean(smeans)
0
subject <- c(1,2,3,4,5)
baseline <- c(140, 138, 150, 148, 135)
week2 <- c(132, 135, 151, 146, 130)
examinations <- data.frame(subject, baseline, week2)
examinations
test <- t.test(examinations$baseline, y=examinations$week2, alt="two-sided", paired = TRUE)
test
test <- t.test(x=examinations$baseline, y=examinations$week2, alt="two-sided", paired = TRUE)
test
test <- t.test(x=examinations$baseline, y=examinations$week2, alt="two.sided", paired = TRUE)
test
pval <- round(test$p.value,3)
pval
n <- 9
μ <- 1100
σ <- 30
quantile = 0.975 # is 95% with 2.5% on both sides of the range
confidenceInterval = μ + c(-1, 1) * qt(quantile, df=n-1) * σ / sqrt(n)
confidenceInterval
n <- 4
x <- 3
test <- binom.test(x=x, n=n, alt="greater")
round(test$p.value,2)
rate <- 1/100
errors <- 10
days <- 1787
test <-  poisson.test(errors, T = days, r = rate, alt="less")
round(test$p.value,2)
σ_p <- (((n_x - 1) * σ_x^2 + (n_y - 1) * σ_y^2)/(n_x + n_y - 2))
pval <- pt((μ_y - μ_x) / (σ_p * (1 / n_x + 1 / n_y)^.5), df=n_y + n_x -2)
pval
n_y <- 9 # subjects treated
n_x <- 9 # subjects placebo
σ_y <- 1.5# kg/m2 std.dev. treated
σ_x <- 1.8# kg/m2 std.dev. placebo
μ_y <- -3#  kg/m2 average difference treated
μ_x <- 1#  kg/m2 average difference placebo
# calculate pooled standard deviation
σ_p <- (((n_x - 1) * σ_x^2 + (n_y - 1) * σ_y^2)/(n_x + n_y - 2))
pval <- pt((μ_y - μ_x) / (σ_p * (1 / n_x + 1 / n_y)^.5), df=n_y + n_x -2)
pval
n <- 100 #subject
μ <- 0.01# m^3 brain volume loss mean
σ <- 0.04# m^3 brain volume loss std. dev.
p <- 0.05 # sign level
pow <- power.t.test(n=n, delta=μ, sd=σ , sig.level=p, type="one.sample", alt="one.sided")$power
round(pow, 2)
μ <- 0.01# m^3 brain volume loss mean
σ <- 0.04# m^3 brain volume loss std. dev.
p <- 0.05 # sign level
pow <- 0.9 #power
n <- power.t.test(power=pow, delta=μ, sd=σ , sig.level=p, type="one.sample", alt="one.sided")$n
ceiling(n/10)*10
---
created by: Shi Yunn
---
PA1
==============================
Setting
```{r}
echo = TRUE  # Always make code visible
options(scipen = 1)  # Turn off scientific notations for numbers
```
Loading and preprocessing the data
```{r}
setwd("C:/Users/Asus/Desktop/Data Science Coursera/Reproducible Research/RepData_PeerAssessment1/")
unzip("C:./repdata-data-activity.zip")
activity <- read.csv("activity.csv")
library(dplyr)
```
Removing NA steps from data frame
```{r}
activity1 <- filter(activity, !is.na(steps))
```
Grouping the dataset by date
```{r}
activity_date <- group_by(activity1, date)
```
Calculate the total steps per day
```{r}
activity_steps <- aggregate(steps ~ date, activity1, sum)
colnames(activity_steps) <- c("date", "steps")
head(activity_steps)
```
Plot the histrogram to illustate the number of steps per day
```{r}
library(ggplot2)
ggplot(activity_steps, aes(x=steps)) +
geom_histogram(binwidth = 1000)+
labs(title= " The number of steps taken per day (NA removed",
x = "Num. of steps per day",
y = " Num. of times in day")
```
To calculate the mean and median of the steps taken per day
```{r}
mean(activity_steps$steps)
median(activity_steps$steps)
```
The mean is 10766 and median is 10765
To find what is the average daily activity pattern
```{r}
activity_pattern <- aggregate(activity1$steps,
by = list(interval= activity1$interval),
FUN=mean, na.rm=TRUE)
colnames(activity_pattern) <- c("interval", "steps")
head(activity_pattern)
```
Plot a line graph to track the av. daily activity pattern
```{r}
ggplot(activity_pattern, aes(x=interval, y=steps)) +
geom_line(size=1) +
labs (title= "Av. daily activity pattern(NA removed)", x="Interval", y="Num. of steps")
```
To find out which 5-min interval, on average across all the days in the dataset, contains the maximum number of steps?
```{r}
max_int <- activity_pattern[which.max(activity_pattern$steps),]
```
The answer is 835th interval with a max. of 206 steps
Calculate the total number of missing values in the dataset (i.e. the total number of rows with NAs)
```{r}
na_steps <- sum(is.na(activity$steps))
```
the total number of missing values is 2304
Devise a strategy for filling in all of the missing values in the dataset. In this case, I'm using mean of the steps to replace NA
```{r}
mean_na <- rep(mean(activity$steps, na.rm=TRUE), times=length(which(is.na(activity$steps))))
activity[which(is.na(activity$steps)), "steps"] <- mean_na
head(activity)
```
Make a histogram of the total number of steps taken each day
```{r}
activity_fill <- aggregate(activity$steps, by=list(activity$date), FUN=sum)
colnames(activity_fill) <- c("date", "total")
ggplot(activity_fill, aes(x=total)) +
geom_histogram(binwidth = 1000)+
labs(title= " The number of steps taken per day (NA replaced)",
x = "Num. of steps per day",
y = " Num. of times in day")
```
Calculate and report the mean and median total number of steps taken per day.
```{r}
mean(activity_fill$total)
median(activity_fill$total)
```
The mean and median are 10766. Mean remains unchanged, but median has increased. After filling up the NA values, mean and median become equal.
Create a new factor variable in the dataset with two levels - "weekday" and "weekend"
```{r}
library(lubridate)
```
Lubridate is an R package that makes it easier to work with dates and times.
```{r}
activity <- mutate(activity, weekend=factor(weekdays(ymd(date)) %in% c("Saturday", "Sunday")))
```
group by weekend and interval
```{r,echo=TRUE}
grp_activity <- group_by(activity, weekend, interval)
grp_activity_mean <- group_by(grp_activity, steps=mean(steps))
```
Make a panel plot containing a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) to show the differences between weekday and weekend
```{r, echo=TRUE}
wday <- ggplot(data=subset(grp_activity_mean, weekend==FALSE), aes(x=interval, y=steps)) + geom_line() +
ggtitle("Weekday")
wend <- ggplot(data=subset(grp_activity_mean, weekend==TRUE), aes(x=interval, y=steps)) + geom_line() +
ggtitle("Weekend")
```
to compare both plots
```{r}
library(gridExtra)
grid.arrange(wday, wend, ncol=1)
```
Generate PA1_template.md and PA1_template.html files
```{r}
install.packages('knitr', dependencies = TRUE)
library(knitr)
knit2html("PA1_template.Rmd")
install.packages("knitr", dependencies = TRUE)
install.packages("knitr", dependencies = TRUE)
install.packages("knitr", dependencies = TRUE)
---
created by: Shi Yunn
---
PA1
==============================
Setting
```{r}
echo = TRUE  # Always make code visible
options(scipen = 1)  # Turn off scientific notations for numbers
```
Loading and preprocessing the data
```{r}
setwd("C:/Users/Asus/Desktop/Data Science Coursera/Reproducible Research/RepData_PeerAssessment1/")
unzip("C:./repdata-data-activity.zip")
activity <- read.csv("activity.csv")
library(dplyr)
```
Removing NA steps from data frame
```{r}
activity1 <- filter(activity, !is.na(steps))
```
Grouping the dataset by date
```{r}
activity_date <- group_by(activity1, date)
```
Calculate the total steps per day
```{r}
activity_steps <- aggregate(steps ~ date, activity1, sum)
colnames(activity_steps) <- c("date", "steps")
head(activity_steps)
```
Plot the histrogram to illustate the number of steps per day
```{r}
library(ggplot2)
ggplot(activity_steps, aes(x=steps)) +
geom_histogram(binwidth = 1000)+
labs(title= " The number of steps taken per day (NA removed",
x = "Num. of steps per day",
y = " Num. of times in day")
```
To calculate the mean and median of the steps taken per day
```{r}
mean(activity_steps$steps)
median(activity_steps$steps)
```
The mean is 10766 and median is 10765
To find what is the average daily activity pattern
```{r}
activity_pattern <- aggregate(activity1$steps,
by = list(interval= activity1$interval),
FUN=mean, na.rm=TRUE)
colnames(activity_pattern) <- c("interval", "steps")
head(activity_pattern)
```
Plot a line graph to track the av. daily activity pattern
```{r}
ggplot(activity_pattern, aes(x=interval, y=steps)) +
geom_line(size=1) +
labs (title= "Av. daily activity pattern(NA removed)", x="Interval", y="Num. of steps")
```
To find out which 5-min interval, on average across all the days in the dataset, contains the maximum number of steps?
```{r}
max_int <- activity_pattern[which.max(activity_pattern$steps),]
```
The answer is 835th interval with a max. of 206 steps
Calculate the total number of missing values in the dataset (i.e. the total number of rows with NAs)
```{r}
na_steps <- sum(is.na(activity$steps))
```
the total number of missing values is 2304
Devise a strategy for filling in all of the missing values in the dataset. In this case, I'm using mean of the steps to replace NA
```{r}
mean_na <- rep(mean(activity$steps, na.rm=TRUE), times=length(which(is.na(activity$steps))))
activity[which(is.na(activity$steps)), "steps"] <- mean_na
head(activity)
```
Make a histogram of the total number of steps taken each day
```{r}
activity_fill <- aggregate(activity$steps, by=list(activity$date), FUN=sum)
colnames(activity_fill) <- c("date", "total")
ggplot(activity_fill, aes(x=total)) +
geom_histogram(binwidth = 1000)+
labs(title= " The number of steps taken per day (NA replaced)",
x = "Num. of steps per day",
y = " Num. of times in day")
```
Calculate and report the mean and median total number of steps taken per day.
```{r}
mean(activity_fill$total)
median(activity_fill$total)
```
The mean and median are 10766. Mean remains unchanged, but median has increased. After filling up the NA values, mean and median become equal.
Create a new factor variable in the dataset with two levels - "weekday" and "weekend"
```{r}
library(lubridate)
```
Lubridate is an R package that makes it easier to work with dates and times.
```{r}
activity <- mutate(activity, weekend=factor(weekdays(ymd(date)) %in% c("Saturday", "Sunday")))
```
group by weekend and interval
```{r,echo=TRUE}
grp_activity <- group_by(activity, weekend, interval)
grp_activity_mean <- group_by(grp_activity, steps=mean(steps))
```
Make a panel plot containing a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) to show the differences between weekday and weekend
```{r, echo=TRUE}
wday <- ggplot(data=subset(grp_activity_mean, weekend==FALSE), aes(x=interval, y=steps)) + geom_line() +
ggtitle("Weekday")
wend <- ggplot(data=subset(grp_activity_mean, weekend==TRUE), aes(x=interval, y=steps)) + geom_line() +
ggtitle("Weekend")
```
to compare both plots
```{r}
library(gridExtra)
grid.arrange(wday, wend, ncol=1)
```
Generate PA1_template.md and PA1_template.html files
```{r}
install.packages('knitr', dependencies = TRUE)
library(knitr)
knit2html("PA1_template.Rmd")
